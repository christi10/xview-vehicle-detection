{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc41fb5",
   "metadata": {},
   "source": [
    "# xView Vehicle Detection ‚Äî Notebook\n",
    "\n",
    "This notebook trains/evaluates a YOLO detector (Ultralytics + PyTorch) on the provided xView tiles and runs inference on `future_pass_images/`.\n",
    "\n",
    "Assumptions:\n",
    "- Dataset is COCO-style in `annotations.json` with categories including `small-vehicle` and `large-vehicle`.\n",
    "- Images are under `images/` (train/val) and `future_pass_images/` (inference).\n",
    "- For speed, we use a lightweight model (yolov8n) and minimal epochs by default.\n",
    "\n",
    "Outputs:\n",
    "- Evaluation metrics (precision, recall, mAP).\n",
    "- Per-image counts of small vs large vehicles in `future_pass_images/`.\n",
    "- A `results.json` artifact under `outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbeb691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/kristjantabakou/Desktop/assesment2\n"
     ]
    }
   ],
   "source": [
    "# Environment and imports\n",
    "from pathlib import Path\n",
    "import json, glob\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve().parents[0] if (Path.cwd().name == 'notebooks') else Path.cwd().resolve()\n",
    "print('Repo root:', REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ffe79",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "We read training and dataset configs to align with the repo pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1576882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'model': 'yolov8n',\n",
       "  'imgsz': 512,\n",
       "  'epochs': 5,\n",
       "  'batch': 16,\n",
       "  'patience': 20,\n",
       "  'lr0': 0.01,\n",
       "  'weight_decay': 0.0005,\n",
       "  'augment': True,\n",
       "  'seed': 42},\n",
       " {'path': '.',\n",
       "  'train': 'images',\n",
       "  'val': 'images',\n",
       "  'names': [],\n",
       "  'annotations': 'annotations.json',\n",
       "  'splits': {'train': 'splits/train.txt', 'val': 'splits/val.txt'}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cfg = REPO_ROOT / 'configs' / 'train.yaml'\n",
    "data_cfg = REPO_ROOT / 'configs' / 'dataset.yaml'\n",
    "with open(train_cfg) as f: train = yaml.safe_load(f)\n",
    "with open(data_cfg) as f: data = yaml.safe_load(f)\n",
    "train, data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bccf1d",
   "metadata": {},
   "source": [
    "## Load Trained Model (or Train Quickly)\n",
    "We load the latest `best.pt` from `outputs/runs/`. If none exists, you can trigger a short training run separately via CLI or add code here to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101e0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: /Users/kristjantabakou/Desktop/assesment2/outputs/runs/train4/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# Find latest trained weights\n",
    "candidates = glob.glob(str(REPO_ROOT / 'outputs' / 'runs' / '**' / 'weights' / 'best.pt'), recursive=True)\n",
    "assert candidates, 'No trained weights found. Please run training via CLI or add training cell.'\n",
    "candidates.sort(key=lambda p: Path(p).stat().st_mtime, reverse=True)\n",
    "model_path = Path(candidates[0])\n",
    "print('Using model:', model_path)\n",
    "model = YOLO(str(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a4caa",
   "metadata": {},
   "source": [
    "## Evaluation on Validation Split\n",
    "We evaluate the model using Ultralytics' built-in `val()` to obtain overall metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e329ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.199 üöÄ Python-3.13.5 torch-2.8.0 CPU (Apple M4 Pro)\n",
      "Model summary (fused): 72 layers, 3,010,133 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2345.4¬±126.8 MB/s, size: 1200.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/kristjantabakou/Desktop/assesment2/labels.cache... 101 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 101/101 526.2Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 0.7it/s 10.0s.6ss\n",
      "                   all        101       4159       0.67     0.0485     0.0373     0.0135\n",
      "              building         73       2457      0.309      0.511      0.298      0.121\n",
      "         small-vehicle         60       1345      0.397       0.12       0.16     0.0439\n",
      "         large-vehicle         37        182          1          0     0.0125    0.00481\n",
      "           vehicle-lot          6          6          1          0          0          0\n",
      "shipping-container-lot          4         18          1          0          0          0\n",
      "                 tower          3          3          0          0          0          0\n",
      "               trailer          2         35          0          0          0          0\n",
      "              facility         18         45          0          0          0          0\n",
      "                  shed          4          4          1          0          0          0\n",
      "      damaged-building          3          3          1          0          0          0\n",
      "                 pylon          3          3          1          0          0          0\n",
      "                  ship         19         54          1          0     0.0139    0.00552\n",
      "              hut/tent          4          4          1          0          0          0\n",
      "Speed: 0.9ms preprocess, 72.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/kristjantabakou/Desktop/assesment2/notebooks/runs/detect/val\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics/precision(B)': 0.6697576282630835,\n",
       " 'metrics/recall(B)': 0.04853039334023034,\n",
       " 'metrics/mAP50(B)': 0.03727641065924193,\n",
       " 'metrics/mAP50-95(B)': 0.013462994559132966,\n",
       " 'fitness': 0.013462994559132966}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a minimal dataset YAML pointing to split lists and category names\n",
    "# We'll derive names from model.names for simplicity here.\n",
    "names = [model.names[i] for i in sorted(model.names.keys())] if isinstance(model.names, dict) else list(model.names)\n",
    "val_list = REPO_ROOT / data.get('splits', {}).get('val', 'splits/val.txt')\n",
    "tmp_yaml = REPO_ROOT / 'outputs' / 'tmp_dataset_nb.yaml'\n",
    "payload = {\n",
    "    'train': str(val_list.resolve()),\n",
    "    'val': str(val_list.resolve()),\n",
    "    'names': names,\n",
    "    'nc': len(names),\n",
    "}\n",
    "tmp_yaml.parent.mkdir(parents=True, exist_ok=True)\n",
    "tmp_yaml.write_text(yaml.safe_dump(payload))\n",
    "\n",
    "metrics = model.val(data=str(tmp_yaml))\n",
    "metrics_dict = metrics.results_dict\n",
    "metrics_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512f980",
   "metadata": {},
   "source": [
    "## Inference on `future_pass_images/` and Vehicle Counting\n",
    "We run the detector on each future image and count `small-vehicle` and `large-vehicle` detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f300d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1m/Users/kristjantabakou/Desktop/assesment2/outputs/vis/infer_nb\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " [{'image_id': 'xView_1132_1.tif',\n",
       "   'small_vehicle_count': 3,\n",
       "   'large_vehicle_count': 0},\n",
       "  {'image_id': 'xView_1132_3.tif',\n",
       "   'small_vehicle_count': 33,\n",
       "   'large_vehicle_count': 0},\n",
       "  {'image_id': 'xView_1182_5.tif',\n",
       "   'small_vehicle_count': 5,\n",
       "   'large_vehicle_count': 0}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "future_dir = REPO_ROOT / 'future_pass_images'\n",
    "assert future_dir.exists(), 'future_pass_images directory missing'\n",
    "\n",
    "pred = model.predict(\n",
    "    source=str(future_dir),\n",
    "    conf=0.25,\n",
    "    iou=0.45,\n",
    "    save=True,\n",
    "    project=str(REPO_ROOT / 'outputs' / 'vis'),\n",
    "    name='infer_nb',\n",
    "    save_txt=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Map class ids to names\n",
    "names_map = model.names if isinstance(model.names, dict) else {i:n for i,n in enumerate(model.names)}\n",
    "results_list = []\n",
    "for r in pred:\n",
    "    img_name = Path(r.path).name\n",
    "    small, large = 0, 0\n",
    "    for b in (r.boxes or []):\n",
    "        cls_id = int(b.cls[0].item()) if b.cls is not None else -1\n",
    "        cname = names_map.get(cls_id, str(cls_id))\n",
    "        if cname in ('small-vehicle', 'small_vehicle', 'smallvehicle'):\n",
    "            small += 1\n",
    "        elif cname in ('large-vehicle', 'large_vehicle', 'largevehicle'):\n",
    "            large += 1\n",
    "    results_list.append({\n",
    "        'image_id': img_name,\n",
    "        'small_vehicle_count': int(small),\n",
    "        'large_vehicle_count': int(large),\n",
    "    })\n",
    "\n",
    "len(results_list), results_list[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bf368",
   "metadata": {},
   "source": [
    "## Build `results.json`\n",
    "We assemble the final JSON file with per-image counts and overall metrics from evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b929f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /Users/kristjantabakou/Desktop/assesment2/outputs/results.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"results\": [\\n    {\\n      \"image_id\": \"xView_1132_1.tif\",\\n      \"small_vehicle_count\": 3,\\n      \"large_vehicle_count\": 0\\n    },\\n    {\\n      \"image_id\": \"xView_1132_3.tif\",\\n      \"small_vehicle_count\": 33,\\n      \"large_vehicle_count\": 0\\n    },\\n    {\\n      \"image_id\": \"xView_1182_5.tif\",\\n      \"small_vehicle_count\": 5,\\n      \"large_vehicle_count\": 0\\n    },\\n    {\\n      \"image_id\": \"xView_1268_15.tif\",\\n      \"small_vehicle_count\": 0,\\n      \"large_vehicle_count\": 0\\n    },\\n    {\\n      \"image_id\": \"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall = {\n",
    "    'train': {\n",
    "        'average_precision': float(metrics_dict.get('metrics/precision(B)', 0.0)),\n",
    "        'average_recall': float(metrics_dict.get('metrics/recall(B)', 0.0)),\n",
    "        'average_mAP50': float(metrics_dict.get('metrics/mAP50(B)', 0.0)),\n",
    "        'average_mAP50_95': float(metrics_dict.get('metrics/mAP50-95(B)', 0.0)),\n",
    "        # 'average_IoU': Not directly provided by Ultralytics summary; can be computed from per-class if needed.\n",
    "    }\n",
    "}\n",
    "out = {\n",
    "    'results': results_list,\n",
    "    'overall_metrics': overall,\n",
    "}\n",
    "out_path = REPO_ROOT / 'outputs' / 'results.json'\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_path.write_text(json.dumps(out, indent=2))\n",
    "print('Wrote', out_path)\n",
    "out_path.read_text()[:500]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
